# Personal-Neural-Net
A customizable neural net as an ongoing project

My intent is to continuously add functionality as long as I'm studying/working with ML. It's primarily for my own understanding. I'm only using NumPy to compute forward and backward propagation, no high-level APIs unless I'm importing a dataset.

# Current Progress:
 - Initializer
 - Layer constructor
 - ReLU activation function
 - MSE function
 - Forward Propagation
 - Fit method == training
 - ReLU GD
 - Basic backprop
 
 # To-do:
 - Implement backprop with softmax GD
 - Revise ReLU GD
 - Test on MNIST
 - Implement visualization methods
