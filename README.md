# Personal-Neural-Net
A customizable neural net as an ongoing project

My intent is to continuously add functionality as long as I'm studying/working with ML. It's primarily for my own understanding. I'm only using NumPy to compute forward and backward propagation, no high-level APIs unless I'm importing a dataset.

# Current Progress:
 - Initializer
 - Layer constructor
 - ReLU activation function
 - MSE function
 - Forward Propagation
 - Fit method == training
 - ReLU GD
 - Basic backprop
 - Predict method
 - Accuracy method
 
 # To-do:
 - Implement backprop with softmax GD
 - Revise ReLU GD
 - Test on MNIST
  - Debug dimensions mismatch in forward prop
 - Implement visualization methods
